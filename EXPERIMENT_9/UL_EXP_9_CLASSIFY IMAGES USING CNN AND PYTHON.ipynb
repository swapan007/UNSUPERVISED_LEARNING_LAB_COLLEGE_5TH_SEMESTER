{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UL_EXP_9_CLASSIFY IMAGES USING CNN AND PYTHON.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPZFhe0tb2aByMmBNnL3ccc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Lsx_8mIad_AT","executionInfo":{"status":"ok","timestamp":1640535185770,"user_tz":-330,"elapsed":833,"user":{"displayName":"Swapan Chetri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4hpHRzBZkNvL-iePxKAVZfN99JFPtcC8uEhIv4g=s64","userId":"09956080202946625324"}}},"outputs":[],"source":["# import the necessary libraries which are required for performing CNN tasks"]},{"cell_type":"code","source":["import numpy as np\n","%matplotlib inline\n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","tf.compat.v1.set_random_seed(2019)"],"metadata":{"id":"IociaBhof85V","executionInfo":{"status":"ok","timestamp":1640535256330,"user_tz":-330,"elapsed":2892,"user":{"displayName":"Swapan Chetri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4hpHRzBZkNvL-iePxKAVZfN99JFPtcC8uEhIv4g=s64","userId":"09956080202946625324"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# form the CNN model"],"metadata":{"id":"UNg9_uIPgBN1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (180,180,3)) ,\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Flatten(), \n","    tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n","    tf.keras.layers.Dropout(0.1,seed = 2019),\n","    tf.keras.layers.Dense(400,activation =\"relu\"),\n","    tf.keras.layers.Dropout(0.3,seed = 2019),\n","    tf.keras.layers.Dense(300,activation=\"relu\"),\n","    tf.keras.layers.Dropout(0.4,seed = 2019),\n","    tf.keras.layers.Dense(200,activation =\"relu\"),\n","    tf.keras.layers.Dropout(0.2,seed = 2019),\n","    tf.keras.layers.Dense(5,activation = \"softmax\")   #Adding the Output Layer\n","])"],"metadata":{"id":"z_p7QQXPgG9A","executionInfo":{"status":"ok","timestamp":1640535262560,"user_tz":-330,"elapsed":943,"user":{"displayName":"Swapan Chetri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4hpHRzBZkNvL-iePxKAVZfN99JFPtcC8uEhIv4g=s64","userId":"09956080202946625324"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["A convoluted image can be too large and so it is reduced without losing features or patterns, so pooling is done.\n","\n","Here Creating a Neural network is to initialize the network using the Sequential model from Keras.\n","Flatten()- Flattening transforms a two-dimensional matrix of features into a vector of features."],"metadata":{"id":"oK4NywLqgZZe"}},{"cell_type":"markdown","source":["### summary of the CNN model"],"metadata":{"id":"ny7YxZfGhdfz"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PnFit3SlgtsS","executionInfo":{"status":"ok","timestamp":1640535326689,"user_tz":-330,"elapsed":19,"user":{"displayName":"Swapan Chetri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4hpHRzBZkNvL-iePxKAVZfN99JFPtcC8uEhIv4g=s64","userId":"09956080202946625324"}},"outputId":"728e955a-4e1c-45b8-8e9a-1cca9edf5632"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 178, 178, 16)      448       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 89, 89, 16)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 87, 87, 32)        4640      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 43, 43, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 41, 41, 64)        18496     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 20, 20, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 18, 18, 128)       73856     \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 9, 9, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 10368)             0         \n","                                                                 \n"," dense (Dense)               (None, 550)               5702950   \n","                                                                 \n"," dropout (Dropout)           (None, 550)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 400)               220400    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 400)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 300)               120300    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 300)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 200)               60200     \n","                                                                 \n"," dropout_3 (Dropout)         (None, 200)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 5)                 1005      \n","                                                                 \n","=================================================================\n","Total params: 6,202,295\n","Trainable params: 6,202,295\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n","adam=Adam(lr=0.001)\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YXScIa8ChnlN","executionInfo":{"status":"ok","timestamp":1640535343469,"user_tz":-330,"elapsed":473,"user":{"displayName":"Swapan Chetri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4hpHRzBZkNvL-iePxKAVZfN99JFPtcC8uEhIv4g=s64","userId":"09956080202946625324"}},"outputId":"2eb134be-990e-483f-c0a6-b4b324ec4d72"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["bs=30         #Setting batch size\n","train_dir = \"D:/Data Science/Image Datasets/FastFood/train/\"   #Setting training directory\n","validation_dir = \"D:/Data Science/Image Datasets/FastFood/test/\"   #Setting testing directory\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator \n","# All images will be rescaled by 1./255.\n","train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n","test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n","# Flow training images in batches of 20 using train_datagen generator\n","#Flow_from_directory function lets the classifier directly identify the labels from the name of the directories the image lies in\n","train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(180,180))\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator = test_datagen.flow_from_directory(validation_dir,\n","                                                         batch_size=bs,\n","                                                         class_mode  = 'categorical',\n","                                                         target_size=(180,180))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416},"id":"AdpYLfoVhrqk","executionInfo":{"status":"error","timestamp":1640535367165,"user_tz":-330,"elapsed":47,"user":{"displayName":"Swapan Chetri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4hpHRzBZkNvL-iePxKAVZfN99JFPtcC8uEhIv4g=s64","userId":"09956080202946625324"}},"outputId":"52850328-3018-463f-b86b-7399a7846c9d"},"execution_count":9,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-8a928f5f4587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Flow training images in batches of 20 using train_datagen generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Flow_from_directory function lets the classifier directly identify the labels from the name of the directories the image lies in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# Flow validation images in batches of 20 using test_datagen generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m validation_generator =  test_datagen.flow_from_directory(validation_dir,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m   def flow_from_dataframe(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/Data Science/Image Datasets/FastFood/train/'"]}]},{"cell_type":"code","source":["history = model.fit(train_generator,\n","                    validation_data=validation_generator,\n","                    steps_per_epoch=150 // bs,\n","                    epochs=30,\n","                    validation_steps=50 // bs,\n","                    verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"O2G8MGAjhw4R","executionInfo":{"status":"error","timestamp":1640535382338,"user_tz":-330,"elapsed":26,"user":{"displayName":"Swapan Chetri","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh4hpHRzBZkNvL-iePxKAVZfN99JFPtcC8uEhIv4g=s64","userId":"09956080202946625324"}},"outputId":"8758f70e-b2a0-40ed-d93f-bab36cfc3fac"},"execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-1e4697994690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(train_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"mfyXcFPRh0pe"},"execution_count":null,"outputs":[]}]}